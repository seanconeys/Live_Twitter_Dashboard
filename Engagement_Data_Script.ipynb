{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from datetime import datetime, timedelta\n",
    "from google.oauth2 import service_account\n",
    "import re\n",
    "import time\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "from google.cloud import bigquery\n",
    "import schedule\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='engagment_twitter_dash.log', filemode='w', level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authentication(cons_key, cons_secret, acc_token, acc_secret):\n",
    "    auth = tweepy.OAuthHandler(cons_key, cons_secret)\n",
    "    auth.set_access_token(acc_token, acc_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter API Setup\n",
    "ACC_TOKEN = 'YOUR INFO HERE'\n",
    "ACC_SECRET = 'YOUR INFO HERE'\n",
    "CONS_KEY = 'YOUR INFO HERE'\n",
    "CONS_SECRET = 'YOUR INFO HERE'\n",
    "\n",
    "api = authentication(CONS_KEY,CONS_SECRET,ACC_TOKEN,ACC_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Google Service Account Credentials\n",
    "credentials = service_account.Credentials.from_service_account_file('PATH TO GOOGLE CREDENTIALS')\n",
    "\n",
    "#DBCLIENT INTIALIZATION\n",
    "tweets_table_id = \"TABLE NAME\"\n",
    "keywords_table_id = \"TABLE NAME\"\n",
    "hashtags_table_id = \"TABLE NAME\"\n",
    "company_tweets_table_id = \"TABLE NAME\"\n",
    "replies_table_id = \"TABLE NAME\"\n",
    "followers_table_id = \"TABLE NAME\"\n",
    "project_id = \"PROJECT NAME\"\n",
    "db_client = bigquery.Client(project=project_id, credentials = credentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tweet:\n",
    "    \n",
    "    def clean_tweet(self, tweet_json):\n",
    "        user_removed = re.sub(r'@[A-Za-z0-9]+','',tweet_json.decode('utf-8'))\n",
    "        link_removed = re.sub('https?://[A-Za-z0-9./]+','',user_removed)\n",
    "        number_removed = re.sub('[^a-zA-Z0-9]', ' ', link_removed)\n",
    "        lower_case_tweet= number_removed.lower()\n",
    "        tok = WordPunctTokenizer()\n",
    "        words = tok.tokenize(lower_case_tweet)\n",
    "        clean_tweet = (' '.join(words)).strip()\n",
    "        return clean_tweet\n",
    "    \n",
    "    def get_hashtags(self, tweet_json):\n",
    "        hashtags = []\n",
    "        if tweet_json.entities['hashtags'] != []:\n",
    "            hashtags = [hashtag[\"text\"] for hashtag in tweet_json.entities['hashtags']]\n",
    "            \n",
    "        return hashtags\n",
    "    \n",
    "    def get_sentiment(self, text):\n",
    "        client = language.LanguageServiceClient(credentials = credentials)\n",
    "        document = types\\\n",
    "                   .Document(content=text,\n",
    "                             type=enums.Document.Type.PLAIN_TEXT)\n",
    "        sentiment= client\\\n",
    "                          .analyze_sentiment(document=document)\\\n",
    "                          .document_sentiment\\\n",
    "                          \n",
    "        return sentiment.score\n",
    "    \n",
    "    def get_keywords(self, text):\n",
    "        keywords = []\n",
    "        \n",
    "        #Verbs, adjs, and nouns\n",
    "        parts_of_speech = [1, 6, 11]\n",
    "        \n",
    "        client = language.LanguageServiceClient(credentials = credentials)\n",
    "        document = types\\\n",
    "                   .Document(content=text,\n",
    "                             type=enums.Document.Type.PLAIN_TEXT)\n",
    "        syntax = client\\\n",
    "                          .analyze_syntax(document=document)\n",
    "        \n",
    "        for token in syntax.tokens:\n",
    "            if token.part_of_speech.tag in parts_of_speech and token.text.content != \"rt\":\n",
    "                keywords.append(token.text.content) \n",
    "                          \n",
    "        return keywords\n",
    "\n",
    "\n",
    "    \n",
    "    def __init__(self, tweet_json):\n",
    "        self.json = tweet_json\n",
    "    \n",
    "    def get_last_company_tweet_primary_id(self):\n",
    "        query = (\"\"\"\n",
    "            SELECT MAX(primary_id)\n",
    "            FROM `TABLE NAME`\n",
    "            \"\"\"\n",
    "            )\n",
    "        query_job = db_client.query(\n",
    "                query\n",
    "            )  \n",
    "\n",
    "        results = query_job.result()\n",
    "\n",
    "        for row in results:\n",
    "            if str(row[0]) == 'None':\n",
    "                return(1)\n",
    "            else:\n",
    "                return(row[0])\n",
    "        \n",
    "   \n",
    "\n",
    "        \n",
    "    def prepare_tweet(self):\n",
    "        self.text = self.clean_tweet(self.json.text.encode('utf-8'))\n",
    "        self.created_at = datetime.timestamp(self.json.created_at)\n",
    "        self.hashtags = self.get_hashtags(self.json)\n",
    "        self.sentiment = self.get_sentiment(self.text)\n",
    "        self.keywords = self.get_keywords(self.text)\n",
    "        self.primary_id = self.json.id\n",
    "        \n",
    "    def prepare_company_tweet(self):\n",
    "        self.text = self.json.text\n",
    "        self.created_at = datetime.timestamp(self.json.created_at)\n",
    "        self.tweet_id = self.json.id\n",
    "        self.primary_id = (self.get_last_company_tweet_primary_id() + 1)\n",
    "        self.favorites = self.json.favorite_count\n",
    "        self.retweets = self.json.retweet_count\n",
    "        \n",
    "    def prepare_reply(self):\n",
    "        self.text = self.clean_tweet(self.json.text.encode('utf-8'))\n",
    "        self.created_at = datetime.timestamp(self.json.created_at)\n",
    "        self.sentiment = self.get_sentiment(self.text)\n",
    "        self.primary_id = self.json.id\n",
    "        self.response_id = self.json.in_reply_to_status_id\n",
    "        \n",
    "    def store_tweet(self):\n",
    "        errors = []\n",
    "       \n",
    "        tweet_rows = [[self.primary_id, self.created_at, self.text, self.sentiment]]\n",
    "        table = db_client.get_table(tweets_table_id)\n",
    "        errors.append(db_client.insert_rows(table, tweet_rows))\n",
    "        \n",
    "        if self.keywords != []:\n",
    "            keyword_rows = [[self.created_at, keyword, self.primary_id] for keyword in self.keywords]\n",
    "            table = db_client.get_table(keywords_table_id)\n",
    "            errors.append(db_client.insert_rows(table, keyword_rows))\n",
    "            \n",
    "        if self.hashtags != []:\n",
    "            hashtag_rows = [[self.created_at, hashtag, self.primary_id] for hashtag in self.hashtags]\n",
    "            table = db_client.get_table(hashtags_table_id)\n",
    "            errors.append(db_client.insert_rows(table, hashtag_rows))\n",
    "        \n",
    "        if errors == True:\n",
    "            logging.error(\"Tweet Storage Error\" + errors)\n",
    "        \n",
    "        return errors\n",
    "    \n",
    "    def store_company_tweet(self):\n",
    "        errors = []\n",
    "       \n",
    "        company_tweets_rows = [[self.primary_id, self.tweet_id, self.created_at, self.text, self.favorites, self.retweets]]\n",
    "        table = db_client.get_table(company_tweets_table_id)\n",
    "        errors.append(db_client.insert_rows(table, company_tweets_rows))\n",
    "    \n",
    "        if errors == True:\n",
    "            logging.error(\"Company Tweet Storage Error\" + errors)\n",
    "            \n",
    "        return errors\n",
    "    \n",
    "    def store_reply(self):\n",
    "        errors = []\n",
    "       \n",
    "        reply_rows = [[self.primary_id, self.response_id, self.created_at, self.text, self.sentiment ]]\n",
    "        table = db_client.get_table(replies_table_id)\n",
    "        errors.append(db_client.insert_rows(table, reply_rows))\n",
    "        \n",
    "        if errors == True:\n",
    "            logging.error(\"Reply Storage Error\" + errors)\n",
    "            \n",
    "        return errors\n",
    "    \n",
    "    def get_data(self):\n",
    "        print(self.text)\n",
    "        print(self.created_at)\n",
    "        print(self.hashtags)\n",
    "        print(self.sentiment)\n",
    "        print(self.keywords)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_followers_primary_id():\n",
    "    try:\n",
    "        query = (\"\"\"\n",
    "            SELECT MAX(primary_id)\n",
    "            FROM `TABLE NAME`\n",
    "            \"\"\"\n",
    "            )\n",
    "        query_job = db_client.query(\n",
    "                query\n",
    "            )  \n",
    "\n",
    "        results = query_job.result()\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(\"Query For Last Reply Primary ID Failed\" + str(e))\n",
    "        \n",
    "    for row in results:\n",
    "        if str(row[0]) == 'None':\n",
    "            logging.warning(\"Last Followers Primary ID Not Found\")\n",
    "            return(0)\n",
    "        else:\n",
    "            return(row[0])\n",
    "            \n",
    "def update_followers():\n",
    "    try:\n",
    "        user = api.get_user('walmart')\n",
    "    except Exception as e:\n",
    "        logging.error(\"Twitter API For User Followers Update Failed\" + str(e))\n",
    "        \n",
    "    errors = []\n",
    "    primary_id = (get_last_followers_primary_id() + 1)  \n",
    "    followers= int(user.followers_count)\n",
    "    created_at = str(datetime.now().timestamp())\n",
    "    reply_rows = [[primary_id, created_at, followers]]\n",
    "    table = db_client.get_table(followers_table_id)\n",
    "    errors.append(db_client.insert_rows(table, reply_rows))\n",
    "    \n",
    "    if errors == True:\n",
    "            logging.error(\"Followers Count Storage Error\" + errors)\n",
    "            \n",
    "    return errors\n",
    "\n",
    "\n",
    "def update_most_recent_status(): \n",
    "    try:\n",
    "        for status in tweepy.Cursor(api.user_timeline, id=\"walmart\").items():\n",
    "            if str(status.in_reply_to_screen_name) == 'None' and ('retweeted_status' in status._json) == False and str(status.retweeted) == 'False' and str(status.is_quote_status) == 'False':             \n",
    "                company_tweet_handler = tweet(status)\n",
    "                company_tweet_handler.prepare_company_tweet()\n",
    "                company_tweet_handler.store_company_tweet()\n",
    "                break\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(\"Twitter API For Most Recent Status Update Failed\" + str(e))\n",
    "        print(e)\n",
    "        pass    \n",
    "\n",
    "def get_last_reply_id():\n",
    "    try:\n",
    "        query = (\"\"\"\n",
    "            SELECT MAX(primary_id)\n",
    "            FROM `TABLE NAME`\n",
    "            \"\"\"\n",
    "            )\n",
    "        query_job = db_client.query(\n",
    "                query\n",
    "            )  \n",
    "\n",
    "        results = query_job.result()\n",
    "   \n",
    "    except Exception as e:\n",
    "        logging.error(\"Query For Last Reply Primary ID Failed\" + str(e))\n",
    "                        \n",
    "    for row in results:\n",
    "        if str(row[0]) == 'None':\n",
    "            logging.warning(\"Last Reply Primary ID Not Found\")\n",
    "            return(1)\n",
    "        else:\n",
    "            return(row[0])\n",
    "        \n",
    "        \n",
    "def get_last_status_id():\n",
    "    try:\n",
    "        last_10_ids = []\n",
    "        \n",
    "        query = (\"\"\"\n",
    "            SELECT tweet_id\n",
    "            FROM `TABLE NAME`\n",
    "            GROUP BY tweet_id\n",
    "            ORDER BY tweet_id DESC\n",
    "            LIMIT 10\n",
    "            \"\"\"\n",
    "        )\n",
    "        query_job = db_client.query(\n",
    "            query\n",
    "        )  \n",
    "\n",
    "        results = query_job.result()\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(\"Query For Last Reply Primary ID Failed\" + str(e))\n",
    "    \n",
    "    for row in results:\n",
    "        if str(row[0]) == 'None':\n",
    "            logging.warning(\"Last Status Primary ID Not Found\") \n",
    "            last_10_ids.append(1)\n",
    "        else:               \n",
    "            last_10_ids.append(row[0])\n",
    "    \n",
    "    return last_10_ids    \n",
    "        \n",
    "def update_replies(most_recent_search_id, last_10_status_ids):\n",
    "    try:\n",
    "        for status in tweepy.Cursor(api.search, q=\"to:walmart\", since_id=most_recent_search_id, result_type='recent', lang='en').items():\n",
    "            if status.in_reply_to_status_id in last_10_status_ids:\n",
    "                reply_handler = tweet(status)\n",
    "                reply_handler.prepare_reply()\n",
    "                reply_handler.store_reply()\n",
    "\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(\"Twitter API For Replies Update Failed\" + str(e))\n",
    "        pass\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_engagement_metrics():\n",
    "    logging.info(\"Engagement Metric Update Started\")\n",
    "    try:\n",
    "        update_followers()\n",
    "        update_most_recent_status()\n",
    "        last_10_status_ids = get_last_status_id()\n",
    "        print(last_10_status_ids)\n",
    "        last_status_id = min(last_10_status_ids)\n",
    "        last_reply_id = get_last_reply_id()\n",
    "        most_recent_search_id = max(last_status_id, last_reply_id)\n",
    "        update_replies(most_recent_search_id,last_10_status_ids)\n",
    "        logging.info(\"Engagement Metric Update Closed\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(\"Engagement Metrics Update Failed\" + str(e))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule.every(2).minutes.do(update_engagement_metrics) \n",
    "while True: \n",
    "    try:\n",
    "        schedule.run_pending() \n",
    "        time.sleep(1) \n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(\"Scheduler Failure\" + str(e))\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
